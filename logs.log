Read configuration file: configurations/PEMS04_astgcn.conf
CUDA: True cuda:0
folder_dir: astgcn_r_h1d0w0_channel1_1.000000e-03
params_path: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03
load file: ./data/PEMS04/PEMS04_r1_d0_w0_astcgn
train: torch.Size([10181, 307, 1, 12]) torch.Size([10181, 307, 12])
val: torch.Size([3394, 307, 1, 12]) torch.Size([3394, 307, 12])
test: torch.Size([3394, 307, 1, 12]) torch.Size([3394, 307, 12])
create params directory experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03
param list:
CUDA	 cuda:0
in_channels	 1
nb_block	 2
nb_chev_filter	 64
nb_time_filter	 64
time_strides	 1
batch_size	 32
graph_signal_matrix_filename	 ./data/PEMS04/PEMS04.npz
start_epoch	 0
epochs	 80
ASTGCN_submodule(
  (BlockList): ModuleList(
    (0): ASTGCN_block(
      (TAt): Temporal_Attention_layer()
      (SAt): Spatial_Attention_layer()
      (cheb_conv_SAt): cheb_conv_withSAt(
        (Theta): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 1x64 (GPU 0)]
        )
      )
      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
      (residual_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))
      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (1): ASTGCN_block(
      (TAt): Temporal_Attention_layer()
      (SAt): Spatial_Attention_layer()
      (cheb_conv_SAt): cheb_conv_withSAt(
        (Theta): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 64x64 (GPU 0)]
        )
      )
      (time_conv): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
      (residual_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
  )
  (final_conv): Conv2d(12, 12, kernel_size=(1, 64), stride=(1, 1))
)
Net's state_dict:
BlockList.0.TAt.U1 	 torch.Size([307])
BlockList.0.TAt.U2 	 torch.Size([1, 307])
BlockList.0.TAt.U3 	 torch.Size([1])
BlockList.0.TAt.be 	 torch.Size([1, 12, 12])
BlockList.0.TAt.Ve 	 torch.Size([12, 12])
BlockList.0.SAt.W1 	 torch.Size([12])
BlockList.0.SAt.W2 	 torch.Size([1, 12])
BlockList.0.SAt.W3 	 torch.Size([1])
BlockList.0.SAt.bs 	 torch.Size([1, 307, 307])
BlockList.0.SAt.Vs 	 torch.Size([307, 307])
BlockList.0.cheb_conv_SAt.Theta.0 	 torch.Size([1, 64])
BlockList.0.cheb_conv_SAt.Theta.1 	 torch.Size([1, 64])
BlockList.0.cheb_conv_SAt.Theta.2 	 torch.Size([1, 64])
BlockList.0.time_conv.weight 	 torch.Size([64, 64, 1, 3])
BlockList.0.time_conv.bias 	 torch.Size([64])
BlockList.0.residual_conv.weight 	 torch.Size([64, 1, 1, 1])
BlockList.0.residual_conv.bias 	 torch.Size([64])
BlockList.0.ln.weight 	 torch.Size([64])
BlockList.0.ln.bias 	 torch.Size([64])
BlockList.1.TAt.U1 	 torch.Size([307])
BlockList.1.TAt.U2 	 torch.Size([64, 307])
BlockList.1.TAt.U3 	 torch.Size([64])
BlockList.1.TAt.be 	 torch.Size([1, 12, 12])
BlockList.1.TAt.Ve 	 torch.Size([12, 12])
BlockList.1.SAt.W1 	 torch.Size([12])
BlockList.1.SAt.W2 	 torch.Size([64, 12])
BlockList.1.SAt.W3 	 torch.Size([64])
BlockList.1.SAt.bs 	 torch.Size([1, 307, 307])
BlockList.1.SAt.Vs 	 torch.Size([307, 307])
BlockList.1.cheb_conv_SAt.Theta.0 	 torch.Size([64, 64])
BlockList.1.cheb_conv_SAt.Theta.1 	 torch.Size([64, 64])
BlockList.1.cheb_conv_SAt.Theta.2 	 torch.Size([64, 64])
BlockList.1.time_conv.weight 	 torch.Size([64, 64, 1, 3])
BlockList.1.time_conv.bias 	 torch.Size([64])
BlockList.1.residual_conv.weight 	 torch.Size([64, 64, 1, 1])
BlockList.1.residual_conv.bias 	 torch.Size([64])
BlockList.1.ln.weight 	 torch.Size([64])
BlockList.1.ln.bias 	 torch.Size([64])
final_conv.weight 	 torch.Size([12, 12, 1, 64])
final_conv.bias 	 torch.Size([12])
Net's total params: 450031
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}]
validation batch 1 / 107, loss: 275.52
validation batch 101 / 107, loss: 331.69
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_0.params
validation batch 1 / 107, loss: 56.63
validation batch 101 / 107, loss: 85.39
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_1.params
validation batch 1 / 107, loss: 35.86
validation batch 101 / 107, loss: 43.43
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_2.params
validation batch 1 / 107, loss: 33.96
validation batch 101 / 107, loss: 42.29
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_3.params
global step: 1000, training loss: 28.46, time: 93.96s
validation batch 1 / 107, loss: 32.11
validation batch 101 / 107, loss: 37.03
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_4.params
validation batch 1 / 107, loss: 30.53
validation batch 101 / 107, loss: 34.31
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_5.params
validation batch 1 / 107, loss: 30.02
validation batch 101 / 107, loss: 33.23
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_6.params
global step: 2000, training loss: 23.62, time: 184.88s
validation batch 1 / 107, loss: 29.85
validation batch 101 / 107, loss: 32.35
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_7.params
validation batch 1 / 107, loss: 29.90
validation batch 101 / 107, loss: 32.47
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_8.params
validation batch 1 / 107, loss: 28.75
validation batch 101 / 107, loss: 32.24
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_9.params
global step: 3000, training loss: 23.61, time: 275.96s
validation batch 1 / 107, loss: 28.62
validation batch 101 / 107, loss: 32.91
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_10.params
validation batch 1 / 107, loss: 28.20
validation batch 101 / 107, loss: 31.38
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_11.params
validation batch 1 / 107, loss: 27.78
validation batch 101 / 107, loss: 31.24
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_12.params
global step: 4000, training loss: 19.40, time: 367.22s
validation batch 1 / 107, loss: 28.85
validation batch 101 / 107, loss: 31.04
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_13.params
validation batch 1 / 107, loss: 27.68
validation batch 101 / 107, loss: 30.56
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_14.params
validation batch 1 / 107, loss: 28.59
validation batch 101 / 107, loss: 30.91
global step: 5000, training loss: 22.23, time: 458.13s
validation batch 1 / 107, loss: 27.59
validation batch 101 / 107, loss: 31.25
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_16.params
validation batch 1 / 107, loss: 27.41
validation batch 101 / 107, loss: 30.67
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_17.params
validation batch 1 / 107, loss: 27.93
validation batch 101 / 107, loss: 31.61
global step: 6000, training loss: 18.72, time: 549.19s
validation batch 1 / 107, loss: 27.53
validation batch 101 / 107, loss: 30.76
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_19.params
validation batch 1 / 107, loss: 27.07
validation batch 101 / 107, loss: 30.40
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_20.params
validation batch 1 / 107, loss: 27.40
validation batch 101 / 107, loss: 30.22
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_21.params
global step: 7000, training loss: 17.98, time: 640.52s
validation batch 1 / 107, loss: 27.13
validation batch 101 / 107, loss: 30.22
validation batch 1 / 107, loss: 27.60
validation batch 101 / 107, loss: 30.37
validation batch 1 / 107, loss: 27.17
validation batch 101 / 107, loss: 30.60
validation batch 1 / 107, loss: 26.80
validation batch 101 / 107, loss: 30.08
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_25.params
global step: 8000, training loss: 21.12, time: 734.36s
validation batch 1 / 107, loss: 27.01
validation batch 101 / 107, loss: 30.65
validation batch 1 / 107, loss: 26.93
validation batch 101 / 107, loss: 30.46
validation batch 1 / 107, loss: 26.85
validation batch 101 / 107, loss: 30.35
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_28.params
global step: 9000, training loss: 20.83, time: 825.67s
validation batch 1 / 107, loss: 26.89
validation batch 101 / 107, loss: 30.32
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_29.params
validation batch 1 / 107, loss: 26.75
validation batch 101 / 107, loss: 30.34
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_30.params
validation batch 1 / 107, loss: 26.63
validation batch 101 / 107, loss: 30.16
global step: 10000, training loss: 20.54, time: 916.84s
validation batch 1 / 107, loss: 26.80
validation batch 101 / 107, loss: 30.19
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_32.params
validation batch 1 / 107, loss: 26.65
validation batch 101 / 107, loss: 30.29
validation batch 1 / 107, loss: 26.68
validation batch 101 / 107, loss: 30.11
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_34.params
global step: 11000, training loss: 18.27, time: 1007.78s
validation batch 1 / 107, loss: 26.50
validation batch 101 / 107, loss: 30.03
validation batch 1 / 107, loss: 26.79
validation batch 101 / 107, loss: 30.21
validation batch 1 / 107, loss: 27.42
validation batch 101 / 107, loss: 30.58
global step: 12000, training loss: 19.99, time: 1098.66s
validation batch 1 / 107, loss: 26.80
validation batch 101 / 107, loss: 30.42
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_38.params
validation batch 1 / 107, loss: 26.65
validation batch 101 / 107, loss: 30.36
validation batch 1 / 107, loss: 26.84
validation batch 101 / 107, loss: 30.21
global step: 13000, training loss: 19.34, time: 1189.54s
validation batch 1 / 107, loss: 26.91
validation batch 101 / 107, loss: 30.54
validation batch 1 / 107, loss: 26.73
validation batch 101 / 107, loss: 30.44
validation batch 1 / 107, loss: 26.51
validation batch 101 / 107, loss: 30.19
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_43.params
global step: 14000, training loss: 21.98, time: 1280.45s
validation batch 1 / 107, loss: 26.79
validation batch 101 / 107, loss: 30.11
validation batch 1 / 107, loss: 26.87
validation batch 101 / 107, loss: 30.29
validation batch 1 / 107, loss: 26.57
validation batch 101 / 107, loss: 30.30
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_46.params
validation batch 1 / 107, loss: 26.88
validation batch 101 / 107, loss: 30.37
global step: 15000, training loss: 19.30, time: 1374.09s
validation batch 1 / 107, loss: 26.36
validation batch 101 / 107, loss: 30.19
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_48.params
validation batch 1 / 107, loss: 26.57
validation batch 101 / 107, loss: 30.51
validation batch 1 / 107, loss: 26.81
validation batch 101 / 107, loss: 30.57
global step: 16000, training loss: 20.96, time: 1464.92s
validation batch 1 / 107, loss: 26.34
validation batch 101 / 107, loss: 30.44
validation batch 1 / 107, loss: 26.70
validation batch 101 / 107, loss: 30.72
validation batch 1 / 107, loss: 26.66
validation batch 101 / 107, loss: 30.20
global step: 17000, training loss: 20.50, time: 1555.71s
validation batch 1 / 107, loss: 26.41
validation batch 101 / 107, loss: 30.26
validation batch 1 / 107, loss: 27.10
validation batch 101 / 107, loss: 30.67
validation batch 1 / 107, loss: 26.36
validation batch 101 / 107, loss: 30.33
global step: 18000, training loss: 20.94, time: 1646.55s
validation batch 1 / 107, loss: 26.68
validation batch 101 / 107, loss: 30.35
validation batch 1 / 107, loss: 26.78
validation batch 101 / 107, loss: 30.26
validation batch 1 / 107, loss: 26.28
validation batch 101 / 107, loss: 30.36
global step: 19000, training loss: 20.19, time: 1737.40s
validation batch 1 / 107, loss: 26.40
validation batch 101 / 107, loss: 30.44
validation batch 1 / 107, loss: 26.45
validation batch 101 / 107, loss: 30.24
validation batch 1 / 107, loss: 26.23
validation batch 101 / 107, loss: 30.29
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_62.params
global step: 20000, training loss: 17.97, time: 1828.31s
validation batch 1 / 107, loss: 27.04
validation batch 101 / 107, loss: 30.86
validation batch 1 / 107, loss: 26.72
validation batch 101 / 107, loss: 30.52
validation batch 1 / 107, loss: 26.35
validation batch 101 / 107, loss: 30.16
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_65.params
global step: 21000, training loss: 21.61, time: 1919.18s
validation batch 1 / 107, loss: 26.33
validation batch 101 / 107, loss: 30.32
validation batch 1 / 107, loss: 26.33
validation batch 101 / 107, loss: 30.42
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_67.params
validation batch 1 / 107, loss: 26.35
validation batch 101 / 107, loss: 30.24
global step: 22000, training loss: 20.72, time: 2010.00s
validation batch 1 / 107, loss: 26.28
validation batch 101 / 107, loss: 30.06
validation batch 1 / 107, loss: 26.79
validation batch 101 / 107, loss: 30.44
validation batch 1 / 107, loss: 26.89
validation batch 101 / 107, loss: 30.58
validation batch 1 / 107, loss: 26.23
validation batch 101 / 107, loss: 30.44
global step: 23000, training loss: 18.06, time: 2103.60s
validation batch 1 / 107, loss: 26.40
validation batch 101 / 107, loss: 30.44
validation batch 1 / 107, loss: 27.33
validation batch 101 / 107, loss: 30.81
validation batch 1 / 107, loss: 26.09
validation batch 101 / 107, loss: 30.14
save parameters to file: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_75.params
global step: 24000, training loss: 16.90, time: 2194.43s
validation batch 1 / 107, loss: 26.17
validation batch 101 / 107, loss: 30.27
validation batch 1 / 107, loss: 26.05
validation batch 101 / 107, loss: 30.23
validation batch 1 / 107, loss: 26.38
validation batch 101 / 107, loss: 30.47
global step: 25000, training loss: 19.83, time: 2285.29s
validation batch 1 / 107, loss: 26.59
validation batch 101 / 107, loss: 30.42
best epoch: 75
load weight from: experiments/PEMS04/astgcn_r_h1d0w0_channel1_1.000000e-03/epoch_75.params
predicting data set batch 1 / 107
predicting data set batch 101 / 107
input: (3394, 307, 1, 12)
prediction: (3394, 307, 12)
data_target_tensor: (3394, 307, 12)
current epoch: 75, predict 0 points
MAE: 17.76
RMSE: 28.38
MAPE: 0.12
current epoch: 75, predict 1 points
MAE: 18.87
RMSE: 30.03
MAPE: 0.13
current epoch: 75, predict 2 points
MAE: 19.73
RMSE: 31.29
MAPE: 0.13
current epoch: 75, predict 3 points
MAE: 20.41
RMSE: 32.30
MAPE: 0.14
current epoch: 75, predict 4 points
MAE: 21.00
RMSE: 33.19
MAPE: 0.14
current epoch: 75, predict 5 points
MAE: 21.59
RMSE: 34.09
MAPE: 0.15
current epoch: 75, predict 6 points
MAE: 22.21
RMSE: 35.02
MAPE: 0.15
current epoch: 75, predict 7 points
MAE: 22.80
RMSE: 35.93
MAPE: 0.15
current epoch: 75, predict 8 points
MAE: 23.33
RMSE: 36.76
MAPE: 0.16
current epoch: 75, predict 9 points
MAE: 24.01
RMSE: 37.71
MAPE: 0.16
current epoch: 75, predict 10 points
MAE: 24.75
RMSE: 38.79
MAPE: 0.17
current epoch: 75, predict 11 points
MAE: 25.68
RMSE: 40.08
MAPE: 0.17
all MAE: 21.84
all RMSE: 34.64
all MAPE: 0.15
[17.757488, 28.384863932882983, 0.12009408, 18.868498, 30.034340087184475, 0.1271726, 19.725538, 31.294604885217435, 0.13311058, 20.40728, 32.30293507187563, 0.13768364, 20.997585, 33.18729585918854, 0.14137076, 21.592884, 34.08859916120692, 0.1454568, 22.21176, 35.01887918557735, 0.14956863, 22.803568, 35.93124775776215, 0.15304813, 23.330532, 36.7637357408765, 0.1568324, 24.0103, 37.71468333245273, 0.16089763, 24.754164, 38.785462918328854, 0.16579218, 25.678305, 40.0825046339968, 0.17231835, 21.844824, 34.636568746503315, 0.14694585]
